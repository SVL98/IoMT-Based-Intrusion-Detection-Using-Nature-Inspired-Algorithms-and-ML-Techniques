{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SVL98/IoMT-Based-Intrusion-Detection-Using-Nature-Inspired-Algorithms-and-ML-Techniques/blob/main/NIA%2BRF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Firely + RF on WUSTL dataset"
      ],
      "metadata": {
        "id": "2CzJ_DCm5rX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
        "\n",
        "def print_metrics(y_true, y_pred):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='macro')\n",
        "    recall = recall_score(y_true, y_pred, average='macro')\n",
        "    f1 = f1_score(y_true, y_pred, average='macro')\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    support = len(y_true)\n",
        "    print(\"\\nüß© Confusion Matrix:\")\n",
        "    print(cm)\n",
        "    print(\"\\nüìä Metrics Summary:\")\n",
        "    print(f\"{'Accuracy':<10} {'Precision':<10} {'Recall':<10} {'F1-Score':<10} {'Support':<10}\")\n",
        "    print(f\"{accuracy:<10.4f} {precision:<10.4f} {recall:<10.4f} {f1:<10.4f} {support:<10}\")\n",
        "\n",
        "# Dataset load and preprocessing (same as your code)\n",
        "file_path = \"/content/wustl-ehms-2020_with_attacks_categories.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "df.drop(columns=['Dir', 'Flgs', 'SrcAddr', 'DstAddr', 'SrcMac', 'DstMac', 'Attack Category'], inplace=True, errors='ignore')\n",
        "df.dropna(subset=['Label'], inplace=True)\n",
        "benign = df[df['Label'] == 0].sample(n=min(14000, df[df['Label'] == 0].shape[0]), random_state=42)\n",
        "attack = df[df['Label'] == 1].sample(n=min(1400, df[df['Label'] == 1].shape[0]), random_state=42)\n",
        "df_sampled = pd.concat([benign, attack]).sample(frac=1.0, random_state=42)\n",
        "X_raw = df_sampled.drop(columns=[\"Label\"])\n",
        "y = df_sampled[\"Label\"].reset_index(drop=True)\n",
        "feature_names = X_raw.columns.tolist()\n",
        "for column in X_raw.select_dtypes(include=['object']).columns:\n",
        "    le = LabelEncoder()\n",
        "    X_raw[column] = le.fit_transform(X_raw[column].astype(str))\n",
        "imp = SimpleImputer(strategy='median')\n",
        "X_imp = imp.fit_transform(X_raw)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_imp)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, stratify=y, random_state=42)\n",
        "num_features = X_train.shape[1]\n",
        "\n",
        "# Fitness\n",
        "def fitness(mask):\n",
        "    mask = np.round(mask).astype(int)\n",
        "    if np.count_nonzero(mask) == 0:\n",
        "        return 0\n",
        "    clf = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "    clf.fit(X_train[:, mask == 1], y_train)\n",
        "    y_pred = clf.predict(X_test[:, mask == 1])\n",
        "    return accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Firefly Algorithm\n",
        "def firefly_algorithm(n=20, max_gen=30, alpha=0.2, beta0=1, gamma=1):\n",
        "    pop = np.random.randint(0, 2, size=(n, num_features))\n",
        "    scores = [fitness(ind) for ind in pop]\n",
        "\n",
        "    for gen in range(max_gen):\n",
        "        for i in range(n):\n",
        "            for j in range(n):\n",
        "                if scores[j] > scores[i]:\n",
        "                    r = np.sum((pop[i] - pop[j]) ** 2)\n",
        "                    beta = beta0 * math.exp(-gamma * r)\n",
        "                    move = alpha * (np.random.rand(num_features) - 0.5)\n",
        "                    pop[i] = np.clip(pop[i] + beta * (pop[j] - pop[i]) + move, 0, 1)\n",
        "                    pop[i] = np.round(pop[i])\n",
        "        scores = [fitness(ind) for ind in pop]\n",
        "    best_idx = np.argmax(scores)\n",
        "    return pop[best_idx], scores[best_idx]\n",
        "\n",
        "print(\"\\n‚ú® Running Firefly Algorithm for Feature Selection...\")\n",
        "best_mask, _ = firefly_algorithm()\n",
        "selected_features = np.where(best_mask == 1)[0]\n",
        "selected_feature_names = [feature_names[i] for i in selected_features]\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train[:, selected_features], y_train)\n",
        "y_pred = model.predict(X_test[:, selected_features])\n",
        "\n",
        "print(f\"\\n‚úÖ Selected {len(selected_features)} features using FA:\")\n",
        "print(selected_feature_names)\n",
        "print(f\"\\nüéØ Accuracy (FA + RF): {accuracy_score(y_test, y_pred) * 100:.2f}%\")\n",
        "print(\"\\nüìÑ Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print_metrics(y_test, y_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUgnPRlh5wwm",
        "outputId": "b7d3e6ad-8961-4df7-eb88-7de845627d2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚ú® Running Firefly Algorithm for Feature Selection...\n",
            "\n",
            "‚úÖ Selected 16 features using FA:\n",
            "['DstBytes', 'DstLoad', 'SIntPkt', 'DIntPkt', 'SIntPktAct', 'DIntPktAct', 'sMaxPktSz', 'dMinPktSz', 'TotBytes', 'Rate', 'Packet_num', 'Temp', 'Pulse_Rate', 'SYS', 'Resp_Rate', 'ST']\n",
            "\n",
            "üéØ Accuracy (FA + RF): 95.62%\n",
            "\n",
            "üìÑ Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.98      2800\n",
            "           1       0.98      0.53      0.69       280\n",
            "\n",
            "    accuracy                           0.96      3080\n",
            "   macro avg       0.97      0.76      0.83      3080\n",
            "weighted avg       0.96      0.96      0.95      3080\n",
            "\n",
            "\n",
            "üß© Confusion Matrix:\n",
            "[[2797    3]\n",
            " [ 132  148]]\n",
            "\n",
            "üìä Metrics Summary:\n",
            "Accuracy   Precision  Recall     F1-Score   Support   \n",
            "0.9562     0.9675     0.7637     0.8316     3080      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ACO+RF"
      ],
      "metadata": {
        "id": "55b6TPbp7VBC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MNB3AynH7maP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
        "\n",
        "# üßÆ Metrics printer\n",
        "def print_metrics(y_true, y_pred):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='macro')\n",
        "    recall = recall_score(y_true, y_pred, average='macro')\n",
        "    f1 = f1_score(y_true, y_pred, average='macro')\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    support = len(y_true)\n",
        "\n",
        "    print(\"\\nüß© Confusion Matrix:\")\n",
        "    print(cm)\n",
        "    print(\"\\nüìä Metrics Summary:\")\n",
        "    print(f\"{'Accuracy':<10} {'Precision':<10} {'Recall':<10} {'F1-Score':<10} {'Support':<10}\")\n",
        "    print(f\"{accuracy:<10.4f} {precision:<10.4f} {recall:<10.4f} {f1:<10.4f} {support:<10}\")\n",
        "\n",
        "# Step 1: Load dataset\n",
        "file_path = \"/content/wustl-ehms-2020_with_attacks_categories.csv\"\n",
        "if not os.path.exists(file_path):\n",
        "    raise FileNotFoundError(f\"File not found: {file_path}\")\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Step 2: Clean and preprocess\n",
        "df.drop(columns=['Dir', 'Flgs', 'SrcAddr', 'DstAddr', 'SrcMac', 'DstMac', 'Attack Category'], inplace=True, errors='ignore')\n",
        "df.dropna(subset=['Label'], inplace=True)\n",
        "\n",
        "# Step 3: Sampling\n",
        "benign = df[df['Label'] == 0].sample(n=min(14000, df[df['Label'] == 0].shape[0]), random_state=42)\n",
        "attack = df[df['Label'] == 1].sample(n=min(1400, df[df['Label'] == 1].shape[0]), random_state=42)\n",
        "df_sampled = pd.concat([benign, attack]).sample(frac=1.0, random_state=42)\n",
        "\n",
        "# Step 4: Feature preprocessing\n",
        "X_raw = df_sampled.drop(columns=[\"Label\"])\n",
        "y = df_sampled[\"Label\"].reset_index(drop=True)\n",
        "feature_names = X_raw.columns.tolist()\n",
        "\n",
        "# Encoding\n",
        "for column in X_raw.select_dtypes(include=['object']).columns:\n",
        "    le = LabelEncoder()\n",
        "    X_raw[column] = le.fit_transform(X_raw[column].astype(str))\n",
        "\n",
        "# Imputation and scaling\n",
        "imp = SimpleImputer(strategy='median')\n",
        "X_imp = imp.fit_transform(X_raw)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_imp)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, stratify=y, random_state=42)\n",
        "num_features = X_train.shape[1]\n",
        "\n",
        "# Step 5: Fitness function\n",
        "def fitness(mask):\n",
        "    mask = np.array(mask)\n",
        "    if np.count_nonzero(mask) < 5:\n",
        "        return 0\n",
        "    clf = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "    clf.fit(X_train[:, mask == 1], y_train)\n",
        "    y_pred = clf.predict(X_test[:, mask == 1])\n",
        "    return accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Step 6: ACO function with enhanced feature selection\n",
        "def aco_feature_selection(num_ants=20, num_iterations=20, evaporation_rate=0.1, alpha=1):\n",
        "    pheromone = np.ones(num_features)\n",
        "    best_mask = None\n",
        "    best_score = 0\n",
        "\n",
        "    for it in range(num_iterations):\n",
        "        all_solutions = []\n",
        "        all_scores = []\n",
        "\n",
        "        for _ in range(num_ants):\n",
        "            probs = pheromone ** alpha\n",
        "            probs /= probs.sum()\n",
        "\n",
        "            # üîß Force selection of 10‚Äì20 features randomly\n",
        "            k = random.randint(10, 20)\n",
        "            selected = np.random.choice(range(num_features), size=k, replace=False, p=probs)\n",
        "            mask = np.zeros(num_features)\n",
        "            mask[selected] = 1\n",
        "\n",
        "            acc = fitness(mask)\n",
        "            all_solutions.append(mask)\n",
        "            all_scores.append(acc)\n",
        "\n",
        "            if acc > best_score:\n",
        "                best_score = acc\n",
        "                best_mask = mask.copy()\n",
        "\n",
        "        # Update pheromone\n",
        "        pheromone *= (1 - evaporation_rate)\n",
        "        for mask, score in zip(all_solutions, all_scores):\n",
        "            pheromone += score * mask\n",
        "\n",
        "        pheromone = np.clip(pheromone, 1e-6, 1e6)\n",
        "        print(f\"Iteration {it + 1}/{num_iterations} | Best Accuracy: {best_score:.4f}\")\n",
        "\n",
        "    return best_mask, best_score\n",
        "\n",
        "# Step 7: Run ACO\n",
        "print(\"\\nüêú Running Ant Colony Optimization for Feature Selection...\")\n",
        "best_mask, best_score = aco_feature_selection()\n",
        "selected_features = np.where(best_mask == 1)[0]\n",
        "selected_feature_names = [feature_names[i] for i in selected_features]\n",
        "\n",
        "# Step 8: Final model\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train[:, selected_features], y_train)\n",
        "y_pred = model.predict(X_test[:, selected_features])\n",
        "\n",
        "# Step 9: Evaluation\n",
        "print(f\"\\n‚úÖ Selected {len(selected_features)} features using ACO:\")\n",
        "print(selected_feature_names)\n",
        "print(f\"\\nüéØ Accuracy (ACO + RF): {accuracy_score(y_test, y_pred) * 100:.2f}%\")\n",
        "print(\"\\nüìÑ Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print_metrics(y_test, y_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdMBW8jVCmAX",
        "outputId": "9b9d65dc-681c-4cd2-a297-cfb7e051cfe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üêú Running Ant Colony Optimization for Feature Selection...\n",
            "Iteration 1/20 | Best Accuracy: 0.9740\n",
            "Iteration 2/20 | Best Accuracy: 0.9740\n",
            "Iteration 3/20 | Best Accuracy: 0.9740\n",
            "Iteration 4/20 | Best Accuracy: 0.9740\n",
            "Iteration 5/20 | Best Accuracy: 0.9740\n",
            "Iteration 6/20 | Best Accuracy: 0.9740\n",
            "Iteration 7/20 | Best Accuracy: 0.9740\n",
            "Iteration 8/20 | Best Accuracy: 0.9740\n",
            "Iteration 9/20 | Best Accuracy: 0.9740\n",
            "Iteration 10/20 | Best Accuracy: 0.9740\n",
            "Iteration 11/20 | Best Accuracy: 0.9740\n",
            "Iteration 12/20 | Best Accuracy: 0.9740\n",
            "Iteration 13/20 | Best Accuracy: 0.9740\n",
            "Iteration 14/20 | Best Accuracy: 0.9740\n",
            "Iteration 15/20 | Best Accuracy: 0.9740\n",
            "Iteration 16/20 | Best Accuracy: 0.9789\n",
            "Iteration 17/20 | Best Accuracy: 0.9789\n",
            "Iteration 18/20 | Best Accuracy: 0.9789\n",
            "Iteration 19/20 | Best Accuracy: 0.9789\n",
            "Iteration 20/20 | Best Accuracy: 0.9789\n",
            "\n",
            "‚úÖ Selected 14 features using ACO:\n",
            "['Sport', 'SrcBytes', 'DstBytes', 'DstGap', 'SIntPkt', 'SIntPktAct', 'DIntPktAct', 'sMaxPktSz', 'TotBytes', 'Loss', 'pDstLoss', 'Packet_num', 'Temp', 'Pulse_Rate']\n",
            "\n",
            "üéØ Accuracy (ACO + RF): 97.99%\n",
            "\n",
            "üìÑ Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99      2800\n",
            "           1       0.97      0.80      0.88       280\n",
            "\n",
            "    accuracy                           0.98      3080\n",
            "   macro avg       0.98      0.90      0.93      3080\n",
            "weighted avg       0.98      0.98      0.98      3080\n",
            "\n",
            "\n",
            "üß© Confusion Matrix:\n",
            "[[2794    6]\n",
            " [  56  224]]\n",
            "\n",
            "üìä Metrics Summary:\n",
            "Accuracy   Precision  Recall     F1-Score   Support   \n",
            "0.9799     0.9771     0.8989     0.9337     3080      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "cuckoo +rf"
      ],
      "metadata": {
        "id": "eyVBg00Srvnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
        "\n",
        "# ------------------ Metric Printer ------------------\n",
        "def print_metrics(y_true, y_pred):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='macro')\n",
        "    recall = recall_score(y_true, y_pred, average='macro')\n",
        "    f1 = f1_score(y_true, y_pred, average='macro')\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    support = len(y_true)\n",
        "    print(\"\\nüß© Confusion Matrix:\")\n",
        "    print(cm)\n",
        "    print(\"\\nüìä Metrics Summary:\")\n",
        "    print(f\"{'Accuracy':<10} {'Precision':<10} {'Recall':<10} {'F1-Score':<10} {'Support':<10}\")\n",
        "    print(f\"{accuracy:<10.4f} {precision:<10.4f} {recall:<10.4f} {f1:<10.4f} {support:<10}\")\n",
        "\n",
        "# ------------------ 1. Load Data ------------------\n",
        "file_path = \"/content/wustl-ehms-2020_with_attacks_categories.csv\"\n",
        "if not os.path.exists(file_path):\n",
        "    raise FileNotFoundError(f\"File not found: {file_path}\")\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# ------------------ 2. Clean & Preprocess ------------------\n",
        "df.drop(columns=['Dir', 'Flgs', 'SrcAddr', 'DstAddr', 'SrcMac', 'DstMac', 'Attack Category'], inplace=True, errors='ignore')\n",
        "df.dropna(subset=['Label'], inplace=True)\n",
        "\n",
        "# ------------------ 3. Sample Data ------------------\n",
        "benign = df[df['Label'] == 0].sample(n=min(14000, df[df['Label'] == 0].shape[0]), random_state=42)\n",
        "attack = df[df['Label'] == 1].sample(n=min(1400, df[df['Label'] == 1].shape[0]), random_state=42)\n",
        "df_sampled = pd.concat([benign, attack]).sample(frac=1.0, random_state=42)\n",
        "\n",
        "# ------------------ 4. Feature Preparation ------------------\n",
        "X_raw = df_sampled.drop(columns=[\"Label\"])\n",
        "y = df_sampled[\"Label\"].reset_index(drop=True)\n",
        "feature_names = X_raw.columns.tolist()\n",
        "\n",
        "for col in X_raw.select_dtypes(include=['object']).columns:\n",
        "    le = LabelEncoder()\n",
        "    X_raw[col] = le.fit_transform(X_raw[col].astype(str))\n",
        "\n",
        "imp = SimpleImputer(strategy='median')\n",
        "X_imp = imp.fit_transform(X_raw)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_imp)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, stratify=y, random_state=42)\n",
        "num_features = X_train.shape[1]\n",
        "\n",
        "# ------------------ 5. Fitness Function ------------------\n",
        "def fitness(solution):\n",
        "    mask = np.array(solution, dtype=int)\n",
        "    if np.count_nonzero(mask) == 0:\n",
        "        return 0.0\n",
        "    selected = mask == 1\n",
        "    clf = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "    clf.fit(X_train[:, selected], y_train)\n",
        "    y_pred = clf.predict(X_test[:, selected])\n",
        "    return accuracy_score(y_test, y_pred)\n",
        "\n",
        "# ------------------ 6. Cuckoo Search Algorithm ------------------\n",
        "def levy_flight(Lambda):\n",
        "    u = np.random.normal(0, 1) * 0.01\n",
        "    v = np.random.normal(0, 1)\n",
        "    step = u / abs(v) ** (1 / Lambda)\n",
        "    return step\n",
        "\n",
        "def cuckoo_search(n=30, pa=0.25, alpha=1.0, generations=30):\n",
        "    nests = [np.random.randint(0, 2, num_features).tolist() for _ in range(n)]\n",
        "    best = nests[0]\n",
        "    best_score = fitness(best)\n",
        "\n",
        "    for gen in range(generations):\n",
        "        for i in range(n):\n",
        "            step_size = levy_flight(1.5)\n",
        "            new_nest = nests[i][:]\n",
        "            for j in range(num_features):\n",
        "                if random.random() < 0.5:\n",
        "                    new_nest[j] = 1 - new_nest[j] if random.random() < abs(step_size) else new_nest[j]\n",
        "            score = fitness(new_nest)\n",
        "            if score > fitness(nests[i]):\n",
        "                nests[i] = new_nest\n",
        "            if score > best_score:\n",
        "                best = new_nest\n",
        "                best_score = score\n",
        "\n",
        "        # Abandon some nests\n",
        "        for i in range(n):\n",
        "            if random.random() < pa:\n",
        "                nests[i] = [random.randint(0, 1) for _ in range(num_features)]\n",
        "    return np.array(best), best_score\n",
        "\n",
        "# ------------------ 7. Run Cuckoo + RF ------------------\n",
        "print(\"\\nüê¶ Running Cuckoo Search for Feature Selection...\")\n",
        "best_mask, best_accuracy = cuckoo_search(n=30, generations=30)\n",
        "selected_features = np.where(best_mask == 1)[0]\n",
        "selected_feature_names = [feature_names[i] for i in selected_features]\n",
        "\n",
        "# ------------------ 8. Final Model ------------------\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train[:, selected_features], y_train)\n",
        "y_pred = model.predict(X_test[:, selected_features])\n",
        "\n",
        "# ------------------ 9. Evaluation ------------------\n",
        "print(f\"\\n‚úÖ Selected {len(selected_features)} features using Cuckoo Search:\")\n",
        "print(selected_feature_names)\n",
        "print(f\"\\nüéØ Accuracy (Cuckoo + RF): {accuracy_score(y_test, y_pred) * 100:.2f}%\")\n",
        "print(\"\\nüìÑ Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print_metrics(y_test, y_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XowXIfBLrxxZ",
        "outputId": "b5588909-a5ab-4cbf-e3aa-31de01b776af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üê¶ Running Cuckoo Search for Feature Selection...\n",
            "\n",
            "‚úÖ Selected 16 features using Cuckoo Search:\n",
            "['Sport', 'SrcBytes', 'DstBytes', 'DstLoad', 'SrcGap', 'DstGap', 'SIntPktAct', 'DIntPktAct', 'sMaxPktSz', 'sMinPktSz', 'pSrcLoss', 'pDstLoss', 'Packet_num', 'Temp', 'SpO2', 'Pulse_Rate']\n",
            "\n",
            "üéØ Accuracy (Cuckoo + RF): 98.02%\n",
            "\n",
            "üìÑ Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99      2800\n",
            "           1       0.97      0.81      0.88       280\n",
            "\n",
            "    accuracy                           0.98      3080\n",
            "   macro avg       0.97      0.90      0.94      3080\n",
            "weighted avg       0.98      0.98      0.98      3080\n",
            "\n",
            "\n",
            "üß© Confusion Matrix:\n",
            "[[2792    8]\n",
            " [  53  227]]\n",
            "\n",
            "üìä Metrics Summary:\n",
            "Accuracy   Precision  Recall     F1-Score   Support   \n",
            "0.9802     0.9737     0.9039     0.9354     3080      \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM3yu/aH4gUFw//BrruZNjo",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}